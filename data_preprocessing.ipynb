{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff9e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hanaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newsID', 'category', 'subcategory', 'title', 'abstract', 'url', 'entities', 'abstract_entities']\n",
      "   newsID   category      subcategory  \\\n",
      "0  N55528  lifestyle  lifestyleroyals   \n",
      "1  N19639     health       weightloss   \n",
      "2  N61837       news        newsworld   \n",
      "3  N53526     health           voices   \n",
      "4  N38324     health          medical   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1                      50 Worst Habits For Belly Fat   \n",
      "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "4  How to Get Rid of Skin Tags, According to a De...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  These seemingly harmless habits are holding yo...   \n",
      "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "3  I felt like I was a fraud, and being an NBA wi...   \n",
      "4  They seem harmless, but there's a very good re...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
      "\n",
      "                                            entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
      "\n",
      "                                   abstract_entities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "3  [{\"Label\": \"National Basketball Association\", ...  \n",
      "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  \n",
      "TF-IDF matrix shape: (48616, 18635)\n",
      "Saved tfidf_vectorizer.pkl and tfidf_matrix.pkl into ../results/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 01_data_preprocessing.ipynb\n",
    "\n",
    "# 1. Imports & Download\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Define the correct column names\n",
    "col_names = [\n",
    "    'newsID',\n",
    "    'category',\n",
    "    'subcategory',\n",
    "    'title',\n",
    "    'abstract',\n",
    "    'url',\n",
    "    'entities',\n",
    "    'abstract_entities'\n",
    "]\n",
    "\n",
    "# 2. Read with header=None and your names\n",
    "file_path = '../data/news.tsv/news.tsv'\n",
    "news = pd.read_csv(\n",
    "    file_path,\n",
    "    sep='\\t',\n",
    "    header=None,       # <-- no header row in the file\n",
    "    names=col_names,   # <-- assign these names in order\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# 3. Verify\n",
    "print(news.columns.tolist())\n",
    "print(news.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Basic cleaning\n",
    "news = news.dropna(subset=['title', 'abstract'])\n",
    "news['text'] = news['title'] + ' ' + news['abstract']\n",
    "\n",
    "# 4. TF-IDF on combined text\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_df=0.8, \n",
    "    min_df=5,\n",
    "    stop_words=stopwords.words('english')\n",
    ")\n",
    "tfidf_matrix = tfidf.fit_transform(news['text'])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "import os, pickle\n",
    "\n",
    "# 1. Ensure the results directory exists\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# 2. Save the fitted TF-IDF vectorizer\n",
    "with open('../results/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# 3. Save the TF-IDF matrix\n",
    "with open('../results/tfidf_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix, f)\n",
    "\n",
    "print(\"Saved tfidf_vectorizer.pkl and tfidf_matrix.pkl into ../results/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
